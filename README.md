### ðŸ©º AI-Based Multimodal Medical Chatbot

This project was developed as part of my Final Year Project at International Islamic University, Islamabad. It is an AI-powered healthcare chatbot designed to accept **voice, image, and text input**, making medical assistance more accessibleâ€”particularly for **deaf and mute individuals**.

ðŸ”§ **Core Technologies:**
- **Whisper (OpenAI)** â€“ Converts user speech into text
- **Meta LLaMA-4 (Groq API)** â€“ Provides real-time AI-generated medical responses
- **ElevenLabs** â€“ Converts text responses back to natural-sounding voice

The chatbot accepts multimodal input, processes it using advanced AI models, and responds with a **written and spoken diagnosis or suggestion**. It aims to support users in real-time basic health interactions, particularly in resource-limited or accessibility-challenged environments.

ðŸ›  **Built With:**
- Python  
- Flask  
- API integration (Whisper, Groq, ElevenLabs)

ðŸ“Œ **Use Cases:**
- Inclusive communication for patients with speech/hearing impairments  
- Remote basic triage or symptom checking  
- Prototype for accessible virtual health assistants

This project showcases the use of **AI for social impact**, emphasizing real-world applications of multimodal processing and voice-based interaction. Educational and demonstration purposes only.
